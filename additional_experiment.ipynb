{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zg0OziR5JYU",
    "outputId": "88d01c30-0a77-4add-d2bb-737925c3c0dd"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# os.environ['TORCH'] = torch.__version__\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "# !pip install ogb\n",
    "# !pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MB8AIt1XhERp",
    "outputId": "c774d020-c80f-432d-eb92-4ed39df9af19"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/SamirMoustafa/visualization-loss-landscape-GNNs.git\n",
    "# !pip install -e visualization-loss-landscape-GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8AJnBbAMiW84"
   },
   "outputs": [],
   "source": [
    "# Restart the runtime if you're using colab\n",
    "from torch_landscape.directions import PcaDirections, RandomDirections, LearnableDirections\n",
    "from torch_landscape.landscape_linear import LinearLandscapeCalculator\n",
    "from torch_landscape.trajectory import TrajectoryCalculator\n",
    "from torch_landscape.utils import clone_parameters, reset_parameters, seed_everything\n",
    "from torch_landscape.visualize import Plotly2dVisualization, VisualizationData\n",
    "from torch_landscape.visualize_options import VisualizationOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PMrV8KQ55Lel"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wQUh8gRZ5b0i"
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(GCNConv(in_channels, 128))  # First layer\n",
    "\n",
    "        for i in range(num_layers - 2):  # Hidden layers\n",
    "            self.layers.append(GCNConv(128, 128))\n",
    "\n",
    "        self.layers.append(GCNConv(128, out_channels))  # Output layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x, edge_index))\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.layers[-1](x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YuJVMaLn5fZV",
    "outputId": "f1964b0a-4d98-4b06-82d2-23c6e4b4ce96"
   },
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "num_layers=3\n",
    "\n",
    "num_runs = 10\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    model = GCN(num_layers=num_layers,\n",
    "                in_channels=dataset.num_features,\n",
    "                out_channels=dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    best_val_acc = 0\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        _, pred = model(data).max(dim=1)\n",
    "        val_correct = float (pred[data.val_mask].eq(data.y[data.val_mask]).sum().item())\n",
    "        val_acc = val_correct / data.val_mask.sum().item()\n",
    "        test_loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask]).item()\n",
    "        test_correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "        test_acc = test_correct / data.test_mask.sum().item()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_loss = test_loss\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "    test_losses.append(best_test_loss)\n",
    "    test_accuracies.append(best_test_acc  * 100)\n",
    "    print(f'Run {run + 1}, Best Validation Accuracy: {best_val_acc}, Test Loss: {best_test_loss}, Test Accuracy: {best_test_acc}')\n",
    "\n",
    "mean_test_loss = np.mean(test_losses)\n",
    "std_test_loss = np.std(test_losses)\n",
    "mean_test_acc = np.mean(test_accuracies)\n",
    "std_test_acc = np.std(test_accuracies)\n",
    "\n",
    "print(f'Mean Test Loss: {mean_test_loss}, Standard Deviation of Test Loss: {std_test_loss}')\n",
    "print(f'Mean Test Accuracy: {mean_test_acc}, Standard Deviation of Test Accuracy: {std_test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXpussZkaKda"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9Lz3vpJaKlt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIQ6_L-saKok"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9eUPzfUaKrb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pj_Ix05WaKuD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBzXolXCXWz5"
   },
   "outputs": [],
   "source": [
    "class GCN_res(torch.nn.Module):\n",
    "    def __init__(self, dataset, hidden=256, num_layers=6):\n",
    "        super(GCN_res, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        self.input_fc = torch.nn.Linear(dataset.num_node_features, hidden)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            self.convs.append(GCNConv(hidden, hidden))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden))\n",
    "\n",
    "        self.out_fc = torch.nn.Linear(hidden, dataset.num_classes)\n",
    "        self.weights = torch.nn.Parameter(torch.randn((len(self.convs))))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        self.input_fc.reset_parameters()\n",
    "        self.out_fc.reset_parameters()\n",
    "        torch.nn.init.normal_(self.weights)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, adj_t = data.x, data.adj_t\n",
    "\n",
    "        x = self.input_fc(x)\n",
    "        x_input = x  # .copy()\n",
    "\n",
    "        layer_out = []  # 保存每一层的结果\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x, inplace=True)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "            if i == 0:\n",
    "                x = x + 0.2 * x_input\n",
    "            else:\n",
    "                x = x + 0.2 * x_input + 0.5 * layer_out[i - 1]\n",
    "            layer_out.append(x)\n",
    "\n",
    "        weight = F.softmax(self.weights, dim=0)\n",
    "        for i in range(len(layer_out)):\n",
    "            layer_out[i] = layer_out[i] * weight[i]\n",
    "\n",
    "        x = sum(layer_out)\n",
    "        x = self.out_fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)[train_idx]\n",
    "    loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    out = model(data)[split_idx['train']]\n",
    "    loss = F.cross_entropy(out, data.y.squeeze(1)[split_idx['train']])\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3qA62EFbvnd",
    "outputId": "0a077179-f4fd-4d15-f80a-bae5bd6cbcf1"
   },
   "outputs": [],
   "source": [
    "num_layers = 8\n",
    "\n",
    "device_id = 0\n",
    "hidden_channels = 256\n",
    "dropout = 0.5\n",
    "lr = 0.01\n",
    "epochs = 500\n",
    "\n",
    "device = f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()  # 对称归一化\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)\n",
    "\n",
    "model = GCN_res(dataset=dataset, hidden=128, num_layers=num_layers).to(device)\n",
    "\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "evaluator = Evaluator(name='ogbn-arxiv')\n",
    "\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "intermediate_results = []\n",
    "best_train_loss = 0\n",
    "best_valid_acc = 0\n",
    "best_test_acc = 0\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in tqdm(range(1, 1 + epochs)):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "            intermediate_results.append((clone_parameters(model.parameters()), loss))\n",
    "\n",
    "    # Update the best validation and test accuracies\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_train_loss = loss\n",
    "        best_valid_acc = valid_acc\n",
    "        best_test_acc = test_acc\n",
    "        best_model_state_dict = model.state_dict()\n",
    "\n",
    "# Print the best test accuracy based on the best validation accuracy\n",
    "print(f'Best Test Accuracy based on Best Validation Accuracy: {100 * best_test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78DkkH4H2Kru",
    "outputId": "c56f551b-f744-440b-c6c6-c2e5bbe5de89"
   },
   "outputs": [],
   "source": [
    "filename_prefix = f\"gcn_res-l{num_layers}-p{sum([p.numel() for p in model.parameters()])}\"\n",
    "title = \"ogbn-arxiv\"\n",
    "output_folder = \"./\"\n",
    "output_file = filename_prefix + title\n",
    "file_path = join(output_folder, output_file)\n",
    "title = title + f\", Loss: {loss:.3f}, Accuracy: {best_valid_acc:.3f}\"\n",
    "\n",
    "directions = LearnableDirections([*model.parameters()], intermediate_results).calculate_directions()\n",
    "\n",
    "options = VisualizationOptions(num_points=20)\n",
    "trajectory = TrajectoryCalculator([*model.parameters()], directions).project_with_loss(intermediate_results)\n",
    "trajectory.set_range_to_fit_trajectory(options)\n",
    "landscape_calculator = LinearLandscapeCalculator(model.parameters(), directions, options=options)\n",
    "landscape = landscape_calculator.calculate_loss_surface_data_model(model, lambda: evaluate(model))\n",
    "Plotly2dVisualization(options).plot(VisualizationData(landscape, trajectory), file_path, title, \"pdf\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
